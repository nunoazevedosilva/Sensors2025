{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensors and Signal Analysis 2025\n",
    "Author: Nuno Azevedo Silva\n",
    "\n",
    "### Week 2 offline work, preparation for Activity 2\n",
    "\n",
    "This notebook is an activity to consolidate the concepts of week 2 and prepare hands-on activity 2 where you will determine the transfer function and calibrate a real-world sensor by yourself. Indeed, week 2 and 3 introduces the most important concepts of signal processing and analysis, but in its essence, it is all about understanding what you should do to compute the transfer function of a sensor.\n",
    "\n",
    "\n",
    "In concept, knowing each applied stimulus $s_i$ (normally well-known standards), one can determine the transfer function \n",
    "\n",
    "$$E_i = F(s_i)$$\n",
    "\n",
    "where $E_i$ is the output of our sensor (can be voltage, shift, frequency, time, etc). To systhematize, your objective is to:\n",
    "1. Estimate $E_i$ (using statistical procedures to observe the statistical distribution and usually apply a central tendency estimator);\n",
    "2. Estimate each associated uncertainty $u_i$;\n",
    "3. Plot the transfer function and characterize your sensor.\n",
    "\n",
    "Finally, having the trasnfer funciont, you can invert the model using curve fitting procedures to determine the calibration curve $C$ that a end-user can utilize has\n",
    "\n",
    "$$ s_m = C(E)$$\n",
    "\n",
    "to obtain a measure for $s_m$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Static Response\n",
    "\n",
    "The static response of a sensor refers to its behavior under steady-state conditions, where the quantity being measured does not change over time. \n",
    "For this activity we'll have the measured signals of 3 sensors A, B and C for a set of 20 stimuli. Each signal corresponds to the measured steady-state response to a given stimuli during 10 seconds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "\n",
    "time = np.loadtxt('time.txt')\n",
    "stimulus = np.loadtxt('stimulus.txt')\n",
    "data_sensorA = np.loadtxt('data_sensorA.txt')\n",
    "data_sensorB = np.loadtxt('data_sensorB.txt')\n",
    "data_sensorC = np.loadtxt('data_sensorC.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:*** Plot the data for each sensor for the signal corresponding to a ginve stimulus (say index 10). Try to obtain something like this:\n",
    "\n",
    "<img src=\"figs/figure1.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sensorA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 and 1.3 Central Tendency, uncertainty and probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what information will you extract from this?\n",
    "\n",
    "Having multiple measures for the same stimulus we have an opportunity for applying statistical methods and extract meaningul information in the most correct mathematical manner. Looking at the probability distribution, mean ($\\mu$), median and standard deviation is a good starting point.\n",
    "\n",
    "----\n",
    "\n",
    "***Exercise:*** Utilizing the hist function of matplotlib plot an histogram for the distribution of the measured signal for a given stimulus for each sensor. In the same graph represent the mean and median. What should you utilize in each?\n",
    "Try to obtain something like this:\n",
    "\n",
    "<img src=\"figs/figure2.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### hint: you may utilize axvline to plot a vertical line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally if the distribution of values is a gaussian / normal distribution, a good estimate for the uncertainty is the standard deviation. Yet, we see this is only the case for the signal 2, whereas signal 1 follows a more uniform distribution. The problem is that the standard deviation is defined as\n",
    "\n",
    "$$\\sigma = \\sqrt{ \\frac{\\sum (E_i - \\mu)^2}{N-1} }$$\n",
    "\n",
    "and while the interval $[\\mu - \\sigma, \\mu +\\sigma]$ contains 68.3\\% for the, this is only valid for the gaussian distribution.\n",
    "\n",
    "-------------------------\n",
    "\n",
    "\n",
    "***Exercise:*** Taking sensor A, B, and C data for the same stimuli, prove this by plotting the standard deviation and interquartile range in the same graphs for the various distributions. An interesting trick for data analysis is to compute the kernel density estimator. \n",
    "\n",
    "Try to obtain something like this:\n",
    "\n",
    "<img src=\"figs/figure3.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### hint: use numpy percentile function, you may utilize axvspan to fill between two vertical lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Sensor A it is a good approximation to consider the standard deviation, but for sensor B a better estimate of the uncertainty maybe to utilize the concept of quantiles, i.e. the cut points that divide the probability distribution. \n",
    "\n",
    "So far we are assuming that we only have type A uncertainties. In the case we had type B one would apply the standard formula\n",
    "$$u = \\sqrt{u_A^2 + u_B^2}$$\n",
    "\n",
    "-------------------------------\n",
    "\n",
    "***Exercise*** Consider a fixed value for u_B (e.g. 0.02) and get an estimate for each sensor, for each measurement $\\{s_i, E_i\\}$. For the present case consider the 95\\% confidence interval: for that, you take $2\\sigma$ for sensor A and 2.5\\% - 97.5\\% percentile for sensor B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "###hint: for cycle to create an output signal and uncertainty for each stimulus for each sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Signal-to-noise Ratio\n",
    "\n",
    "Having an estimate for uncertainty is an opportunity for estimating the Signal to Noise Ratio - SNR. One of the definitions of the SNR is to consider the mean and estimate for the standard deviation\n",
    "For Powers\n",
    "$$SNR = \\frac{P_{signal}}{P_{noise}}$$\n",
    "or in dB\n",
    "$$SNR = 10 \\log_{10} \\frac{P_{signal}}{P_{noise}}$$\n",
    "for amplitudes\n",
    "$$SNR = \\frac{A^{2}_{signal}}{A^{2}_{noise}}$$\n",
    "or in dB\n",
    "$$SNR = 20 \\log_{10} \\frac{A_{signal}}{A_{noise}}$$\n",
    "\n",
    "\n",
    "---------------------------\n",
    "\n",
    "***Exercise*** Estimate the SNR for each sensor for two distinct stimulus. You may utilize the uncertainty as noise level as a ratio and in dB. What do you conclude considering distinct stimulus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Transfer Function and calibration model\n",
    "\n",
    "Having the output signal associated to known stimuli (also called standards), we have the necessary conditions to compute the transfer function for the three sensors.\n",
    "\n",
    "***Exercise:*** Plot the transfer function for each sensor. Utilizing a spline interpolation. Analyze each of the sensors taking into consideration the characteristics we have defined during week 1, namely:\n",
    "- Span, Full-scale Output, Dynamic Range, and Deadband;\n",
    "- Linearity and saturation;\n",
    "- Sensitivity, by computing a numerical derivative.\n",
    "\n",
    "Try to obtain something like this:\n",
    "\n",
    "<img src=\"figs/fig4.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Hint: Plot using errorbar, interpolate using scipy CubicSpline, utilize parameter nu to compute derivative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:*** For sensor C compute a calibration model for the linear region, providing the numerical expression and accuracy.\n",
    "\n",
    "Try to obtain something like this:\n",
    "\n",
    "<img src=\"figs/fig5.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hint: utilize scipy curve_fit for regression\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time Varying signals\n",
    "\n",
    "In contrast to static response, time-varying response can also be the output of your sensor and correspond to all the situations when the amplitude of a signal varies with time.\n",
    "\n",
    "In this next part we will explore how to extract features from these signals that may relate with the applied stimulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just some functions to generate some mockup data to analyze\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tstop = 30\n",
    "time = np.linspace(0,tstop,tstop*1000)\n",
    "dt=time[1]-time[0]\n",
    "\n",
    "def gensignalA(t):\n",
    "    brownian_noise = np.cumsum(np.random.normal(loc=0, scale=0.7*np.sqrt(t[1]-t[0]), size=len(t)))\n",
    "    ff = 5  \n",
    "    ff2 = 0.1\n",
    "    return np.cos(2*np.pi*ff2*t)*(np.cos(2*np.pi*(ff) * t + .0*np.random.random(len(t))) + 0.2*np.random.normal(loc=0, scale=0.7, size=len(t)))\n",
    "\n",
    "def gensignalB(t):\n",
    "    brownian_noise = np.cumsum(np.random.normal(loc=0, scale=0.7*np.sqrt(t[1]-t[0]), size=len(t)))\n",
    "    ff = 5  \n",
    "    ff2 = 0.1\n",
    "    return np.cos(2*np.pi*ff2*t)*np.cos(2*np.pi*(ff) * (t-0.1)) + 1*brownian_noise\n",
    "\n",
    "signalA = gensignalA(time)\n",
    "signalB = gensignalB(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Time Domain Features\n",
    "\n",
    "***Exercise:*** Plot the signalA and compute some time-domain features:\n",
    "- Mean and Median;\n",
    "- Standard Deviation;\n",
    "- Root Mean Square;\n",
    "- Maximum, Minimum, and Peak-to-peak;\n",
    "- Skewness;\n",
    "\n",
    "\n",
    "Try to obtain something like this:\n",
    "\n",
    "<img src=\"figs/fig6.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Frequency Domain Features\n",
    "\n",
    "***Exercise:*** Compute the Fourier transform and the Power spectral density. Compare both. Characterize the type of noise you find in signalB.\n",
    "\n",
    "\n",
    "Try to obtain something like this:\n",
    "\n",
    "<img src=\"figs/fig7.png\" width=\"300\"/> <img src=\"figs/fig8.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise:*** For the same signal compute the Fourier transform and extract some frequency domain features:\n",
    "- Fundamental Frequency;\n",
    "- Spectral Centroid;\n",
    "- Spectral Bandwidth;\n",
    "- Spectral Entropy;\n",
    "\n",
    "Below we have auxiliary functions that provide these features from FFT Magnitude or PSD. Take a look if they are ok and then utilize them to compute the features.\n",
    "Comment the results, are they expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## auxiliary functions  -  take a look to understand them\n",
    "\n",
    "\n",
    "### Feature extraction from magnitude#################################\n",
    "\n",
    "\n",
    "def compute_fundamental_frequency_magnitude(sig, fs):\n",
    "    N = len(sig)\n",
    "    yf = np.fft.fft(sig)\n",
    "    xf = np.linspace(0.0, fs / 2, N // 2)\n",
    "    magnitudes = 2.0 / N * np.abs(yf[:N // 2])\n",
    "    peaks, _ = scipy.signal.find_peaks(magnitudes)\n",
    "    fundamental_freq = xf[peaks][0]  # assuming the first peak is the fundamental frequency\n",
    "    return fundamental_freq\n",
    "\n",
    "\n",
    "def compute_spectral_bandwidth_magnitude(signal, fs):\n",
    "    magnitudes = np.abs(np.fft.rfft(signal))\n",
    "    length = len(signal)\n",
    "    frequencies = np.abs(np.fft.fftfreq(length, 1.0/fs)[:length//2+1])\n",
    "    spectral_centroid = np.sum(frequencies * magnitudes) / np.sum(magnitudes)\n",
    "    spectral_bandwidth = np.sqrt(np.sum(((frequencies - spectral_centroid) ** 2) * magnitudes) / np.sum(magnitudes))\n",
    "    return spectral_bandwidth\n",
    "\n",
    "def compute_spectral_centroid_magnitude(signal, fs):\n",
    "    magnitudes = np.abs(np.fft.rfft(signal))\n",
    "    length = len(signal)\n",
    "    frequencies = np.abs(np.fft.fftfreq(length, 1.0/fs)[:length//2+1])\n",
    "    spectral_centroid = np.sum(frequencies * magnitudes) / np.sum(magnitudes)\n",
    "    return spectral_centroid\n",
    "\n",
    "def compute_spectral_entropy_magnitude(signal, fs):\n",
    "    eps = np.finfo(np.float32).eps\n",
    "    magnitude = np.abs(np.fft.fft(signal)) ** 2\n",
    "    magnitude= magnitude[:len(signal) // 2]\n",
    "    magnitude /= magnitude.sum() + eps  # Normalize\n",
    "    spectral_entropy = -np.sum(magnitude * np.log2(magnitude + eps))\n",
    "    return spectral_entropy\n",
    "\n",
    "## auxiliary functions - take a look to understand them\n",
    "\n",
    "### Feature extraction from Power spectral density\n",
    "\n",
    "def compute_fundamental_frequency_PSD(signal, fs):\n",
    "\n",
    "    f, Pxx = scipy.signal.welch(signal, fs, nperseg=1024)\n",
    "    peaks, _ = scipy.signal.find_peaks(Pxx)\n",
    "    fundamental_freq = f[peaks][0]  # assuming the first peak is the fundamental frequency\n",
    "    return fundamental_freq\n",
    "\n",
    "\n",
    "def compute_spectral_bandwidth_PSD(signal, fs):\n",
    "    f, Pxx = scipy.signal.welch(signal, fs, nperseg=1024)\n",
    "    spectral_centroid = np.sum(f * Pxx) / np.sum(Pxx)\n",
    "    spectral_bandwidth = np.sqrt(np.sum(((f - spectral_centroid) ** 2) * Pxx) / np.sum(Pxx))\n",
    "    return spectral_bandwidth\n",
    "\n",
    "def compute_spectral_centroid_PSD(signal, fs):\n",
    "    f, Pxx = scipy.signal.welch(signal, fs, nperseg=1024)\n",
    "    spectral_centroid = np.sum(f * Pxx) / np.sum(Pxx)\n",
    "    \n",
    "    return spectral_centroid\n",
    "\n",
    "def compute_spectral_entropy_PSD(signal, fs):\n",
    "    eps = np.finfo(np.float32).eps\n",
    "    f, Pxx = scipy.signal.welch(signal, fs, nperseg=1024)\n",
    "    Pxx /= Pxx.sum() + eps  # Normalize\n",
    "    spectral_entropy = -np.sum(Pxx * np.log2(Pxx + eps))\n",
    "    return spectral_entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Correlation\n",
    "\n",
    "***Exercise:*** Computing the correlation between signalA and signalB try to understand if they are correlated and if there is any lag between them. Comment the results\n",
    "\n",
    "You should obtain something like this:\n",
    "\n",
    "<img src=\"figs/fig9.png\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint use numpy correlate with mode='full'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Time-Frequency Analysis\n",
    "\n",
    "***Demonstration:*** Focusing on signalC, use time-frequency analysis tools to construct a spectrogram. Do that using:\n",
    "1. Short-time Fourier Transform;\n",
    "2. Wavelet analysis;\n",
    "\n",
    "Comment the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Here we will generate the signal to get an idea of what we are seeing\n",
    "\n",
    "def s(t):\n",
    "    t0=10\n",
    "    #return np.sin((0.1*t)*t) + np.sin((100/(t+10))*t)\n",
    "    f1=.5\n",
    "    f2=2\n",
    "    f3=4\n",
    "    f4=1\n",
    "    f0=0.5\n",
    "    return (3*np.sin(2*np.pi*f0*t)\n",
    "            +5*np.exp(-(t-t0)**2*0.5)*np.sin(2*np.pi*f1*t) \n",
    "            + 5*np.exp(-(t-30)**2*0.5)*np.sin(2*np.pi*f2*t) \n",
    "             + 5*np.exp(-(t-80)**2*0.5)*np.sin(2*np.pi*f4*t) \n",
    "             +10*np.exp(-(t-50)**2*3)*np.sin(2*np.pi*f3*t) \n",
    "              )* np.exp(-t/600) + np.random.random(len(t))\n",
    "\n",
    "\n",
    "fs = 30  # Sampling frequency\n",
    "t_f  = 100\n",
    "t = np.linspace(0, t_f, fs*t_f)\n",
    "\n",
    "\n",
    "signalC = s(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\pywt\\_cwt.py:117: FutureWarning: Wavelets from the family cmor, without parameters specified in the name are deprecated. The name should takethe form cmorB-C where B and C are floats representing the bandwidth frequency and center frequency, respectively (example: cmor1.5-1.0).\n",
      "  wavelet = DiscreteContinuousWavelet(wavelet)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723f462b1bc9458eba908aee64ee7d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:22: MatplotlibDeprecationWarning: shading='flat' when X and Y have the same dimensions as C is deprecated since 3.3.  Either specify the corners of the quadrilaterals with X and Y, or pass shading='auto', 'nearest' or 'gouraud', or set rcParams['pcolor.shading'].  This will become an error two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "#Hint: utilize the pywt, spectrogram\n",
    "\n",
    "from scipy.signal import spectrogram\n",
    "from scipy import signal\n",
    "import pywt\n",
    "\n",
    "# widths = np.arange(1,61) # Widths to use for the CWT\n",
    "# cwt_result = cwt(signal, ricker, widths)\n",
    "t = np.arange(len(signalC)) / fs\n",
    "\n",
    "coef, freqs = pywt.cwt(signalC, np.arange(1, 61), 'cmor',\n",
    "                       sampling_period=1/fs)\n",
    "\n",
    "# Plotting\n",
    "\n",
    "fig,ax = plt.subplots(3,1,figsize=(6, 6))\n",
    "\n",
    "ax[0].plot(t,signalC)\n",
    "ax[0].set_xlabel('Time [s]')\n",
    "ax[0].set_ylabel('Signal (arb.units)')\n",
    "\n",
    "im = ax[1].pcolor(t, freqs, np.abs(coef), cmap='inferno')\n",
    "\n",
    "#im = ax[1].imshow(np.abs(cwt_result), extent=[t[0], t[-1], widths[-1], widths[0]], origin='upper', cmap='jet', aspect='auto', vmax=np.max(cwt_result), vmin=np.min(cwt_result))\n",
    "plt.colorbar(im,ax=ax[1],label='Magnitude')\n",
    "ax[1].set_xlabel('Time [s]')\n",
    "ax[1].set_ylabel('Frequency [Hz]')\n",
    "ax[1].set_title('Wavelet Spectrogram')\n",
    "ax[1].set_yscale('log')\n",
    "\n",
    "\n",
    "f, t, Sxx = spectrogram(signalC, fs,nperseg=32)\n",
    "im = ax[2].pcolormesh(t, f, (Sxx), shading='gouraud', cmap='inferno')\n",
    "plt.colorbar(im,label='Magnitude')\n",
    "ax[2].set_xlabel('Time [s]')\n",
    "ax[2].set_ylabel('Frequency [Hz]')\n",
    "ax[2].set_title('STFT Spectrogram')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Aliasing\n",
    "\n",
    "***Demonstration:*** Effect of aliasing in the spectral signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05caa0f38f874e34ab5bc76d2a1df3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\signal\\spectral.py:1963: UserWarning: nperseg = 1024 is greater than input length  = 50, using nperseg = 50\n",
      "  .format(nperseg, input_length))\n",
      "c:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\signal\\spectral.py:1963: UserWarning: nperseg = 1024 is greater than input length  = 8, using nperseg = 8\n",
      "  .format(nperseg, input_length))\n",
      "c:\\Users\\nunoa\\Anaconda2\\envs\\py36\\lib\\site-packages\\scipy\\signal\\spectral.py:1963: UserWarning: nperseg = 1024 is greater than input length  = 1000, using nperseg = 1000\n",
      "  .format(nperseg, input_length))\n"
     ]
    }
   ],
   "source": [
    "import scipy.signal\n",
    "# Parameters for the sine wave\n",
    "frequency_of_signal = 5  # frequency of the sine wave in Hz\n",
    "duration = 1  # duration of the signal in seconds\n",
    "\n",
    "# Generate a time array for the continuous signal\n",
    "t_continuous = np.linspace(0, duration, 1000, endpoint=False)  # High resolution for continuous representation\n",
    "signal_continuous = np.sin(2 * np.pi * frequency_of_signal * t_continuous)\n",
    "\n",
    "# Sampling the signal at two different rates\n",
    "sampling_rate_high = 50  # High sampling rate (above Nyquist rate)\n",
    "sampling_rate_low = 8  # Low sampling rate (below Nyquist rate)\n",
    "\n",
    "# Generate sampled time arrays\n",
    "t_sampled_high = np.linspace(0, duration, sampling_rate_high * duration, endpoint=False)\n",
    "t_sampled_low = np.linspace(0, duration, sampling_rate_low * duration, endpoint=False)\n",
    "\n",
    "# Sample the continuous signal\n",
    "signal_sampled_high = np.sin(2 * np.pi * frequency_of_signal * t_sampled_high)\n",
    "signal_sampled_low = np.sin(2 * np.pi * frequency_of_signal * t_sampled_low)\n",
    "\n",
    "# Plotting\n",
    "fig,ax = plt.subplots(2,1,figsize=[6,6])\n",
    "\n",
    "\n",
    "# Plot high sampling rate signal\n",
    "\n",
    "ax[0].plot(t_sampled_high, signal_sampled_high, 'g' ,ls='--',lw=2,marker='o', label='High Sampling Rate')\n",
    "ax[0].plot(t_continuous, signal_continuous, 'b-',lw=0.5, label='Continuous Signal')\n",
    "ax[0].set_title('Aliasing')\n",
    "ax[0].set_xlabel('Time (seconds)')\n",
    "ax[0].set_ylabel('Amplitude (arb.units)')\n",
    "\n",
    "ax[0].plot(t_sampled_low, signal_sampled_low, 'r',ls='--',lw=2,marker='o', label='Low Sampling Rate')\n",
    "\n",
    "ax[0].legend(loc=1)\n",
    "\n",
    "f, Pxx_high = scipy.signal.welch(signal_sampled_high, fs=sampling_rate_high, nperseg=1024)\n",
    "ax[1].plot(f,Pxx_high, 'g' ,ls='-',lw=4,marker='None', label='High Sampling Rate')\n",
    "\n",
    "f, Pxx_low = scipy.signal.welch(signal_sampled_low, fs=sampling_rate_low, nperseg=1024)\n",
    "ax[1].plot(f,Pxx_low, 'r' ,ls='-',lw=2,marker='None', label='Low Sampling Rate')\n",
    "\n",
    "f, Pxx_continuous = scipy.signal.welch(signal_continuous, fs=1/(t_continuous[1]-t_continuous[0]), nperseg=1024)\n",
    "ax[1].plot(f,Pxx_continuous, 'b' ,ls='--',lw=2,marker='None', label='Continuous')\n",
    "ax[1].set_xlabel('f (Hz)')\n",
    "ax[1].set_ylabel('PSD (arb.units)')\n",
    "ax[1].set_xlim(0,30)\n",
    "fig.tight_layout()\n",
    "\n",
    "# Plot low sampling rate signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Filters\n",
    "\n",
    "We introduced 2 types of filter, frequency and time-domain.\n",
    "\n",
    "***Demonstration:*** Filter signalA and signalB using:\n",
    "1. Fourier domain with Butterworth filter.\n",
    "2. Moving-Average;\n",
    "3. Compare the results in the time and spectral signature. Try with distinct signalsC and D and change the parameters of the filter. \n",
    "\n",
    "What do you conclude? When to use one or the other?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e43c099f714f60ac7fc7425f478680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c5e3a80318342b4816b27d5c34a6df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "import scipy.signal\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib widget\n",
    "tstop = 30\n",
    "time = np.linspace(0,tstop,tstop*1000)\n",
    "dt=time[1]-time[0]\n",
    "\n",
    "def gensignalC(t):\n",
    "    ff = 5  \n",
    "    ff2 = 15\n",
    "    return np.cos(2*np.pi*(ff) * t ) + 0.2*np.random.normal(loc=0, scale=0.7, size=len(t)) + np.cos(2*np.pi*ff2*t)\n",
    "\n",
    "\n",
    "signalC = gensignalC(time)\n",
    "\n",
    "def gensignalD(t):\n",
    "    ff = 5  \n",
    "    ff2 = 60\n",
    "    return np.cos(2*np.pi*(ff) * t ) + 0.2*np.random.normal(loc=0, scale=0.7, size=len(t)) + np.cos(2*np.pi*ff2*t)\n",
    "\n",
    "\n",
    "signalD = gensignalD(time)\n",
    "\n",
    "# Function for moving average filter\n",
    "def moving_average_filter(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size) / window_size, mode='same')\n",
    "\n",
    "\n",
    "for signal_to_analyze,data_name in zip([signalC,signalD],['Signal C','Signal D']):\n",
    "\n",
    "    # Parameters\n",
    "    window_size = 100\n",
    "\n",
    "\n",
    "    # Apply the filters\n",
    "    cutoff=7\n",
    "    b, a = butter(N=5, Wn = cutoff, btype='low', analog=False,fs=1/dt)\n",
    "    filtered_signal_butterworth =  lfilter(b, a, signal_to_analyze)\n",
    "    filtered_signal_moving_average = moving_average_filter(signal_to_analyze, window_size)\n",
    "\n",
    "    # Plot the signals\n",
    "    fig,ax = plt.subplots(2,1,figsize=(5, 6))\n",
    "    ax[0].plot(time, signal_to_analyze, label='Noisy Signal', alpha=0.5)\n",
    "    ax[0].plot(time, filtered_signal_butterworth, label='Butterworth Filtered Signal')\n",
    "    ax[0].plot(time, filtered_signal_moving_average, label='Moving Average Filtered Signal', alpha=0.7)\n",
    "    ax[0].set_xlabel('Time [s]')\n",
    "    ax[0].set_ylabel('Amplitude')\n",
    "    ax[0].legend()\n",
    "    ax[0].set_title('Comparison of Butterworth and Moving Average Filters')\n",
    "\n",
    "\n",
    "    frequencies, psd_original = scipy.signal.welch(signal_to_analyze, fs=1/dt, nperseg=1024)\n",
    "    _, psd_butter = scipy.signal.welch(filtered_signal_butterworth, fs=1/dt, nperseg=1024)\n",
    "    _, psd_moving_avg = scipy.signal.welch(filtered_signal_moving_average, fs=1/dt, nperseg=1024)\n",
    "\n",
    "    ax[1].semilogy(frequencies, psd_original, label='Original Signal')\n",
    "    ax[1].semilogy(frequencies, psd_butter, label='Butterworth Filtered Signal')\n",
    "    ax[1].semilogy(frequencies, psd_moving_avg, label='Moving Average Filtered Signal')\n",
    "    ax[1].set_xlabel('Frequency (Hz)')\n",
    "    ax[1].set_ylabel('PSD')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_title('Power Spectral Density Comparison')\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Windowing\n",
    "\n",
    "***Demonstration:*** Observing the effect of windowing. Substitue N by 1000 or 1024. See what happens and comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888f659a9d0c40518fdc7b3b3fe0608e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "fs = 1000  # Sampling frequency in Hz\n",
    "f = 10  # Frequency of the cosine wave in Hz\n",
    "N = 1024  # Number of samples\n",
    "\n",
    "# Time vector\n",
    "t = np.arange(N) / fs\n",
    "\n",
    "# Generate the cosine signal\n",
    "cosine_signal = np.cos(2 * np.pi * f * t)\n",
    "\n",
    "# Apply a Hamming window\n",
    "hamming_window = np.hamming(N)\n",
    "windowed_signal = cosine_signal * hamming_window\n",
    "\n",
    "# Perform the DFT\n",
    "cosine_signal_fft = np.fft.fft(cosine_signal)\n",
    "windowed_signal_fft = np.fft.fft(windowed_signal)\n",
    "\n",
    "# Frequency vector\n",
    "freqs = np.fft.fftfreq(N, 1/fs)\n",
    "\n",
    "# Plot the original and windowed signal\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(t, cosine_signal, label='Original Signal')\n",
    "plt.plot(t, windowed_signal, label='Windowed Signal')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the magnitude spectrum\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(freqs[:N//2], np.abs(cosine_signal_fft[:N//2]), label='Original Signal FFT')\n",
    "plt.plot(freqs[:N//2], np.abs(windowed_signal_fft[:N//2]), label='Windowed Signal FFT')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arduino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
